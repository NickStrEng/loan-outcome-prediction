{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d711589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"data/loan_data_raw.csv\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: loan_data.csv not found. Please download the dataset from Kaggle.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688aba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812634b1",
   "metadata": {},
   "source": [
    "## Data cleaning/formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"loan_status\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Clean whitespace from string columns\n",
    "for col in (\"loan_status\", \"education\", \"self_employed\"):\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Drop the non-predictive Loan_ID column\n",
    "df = df.drop(\"loan_id\", axis=1, errors=\"ignore\")\n",
    "\n",
    "# Convert target variable to binary (1 and 0)\n",
    "df[\"loan_status\"] = df[\"loan_status\"].replace({\"Approved\": 1, \"Rejected\": 0})\n",
    "\n",
    "X = df.copy().drop(\"loan_status\", axis=1)\n",
    "y = df.copy()[\"loan_status\"]\n",
    "\n",
    "# Target class ratio\n",
    "print(y.value_counts(normalize=True))\n",
    "\n",
    "# Split data into training and test sets (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"\\nTraining samples: {len(X_train)} \\nTest samples: {len(X_test)}\")\n",
    "\n",
    "# Define Feature Types for Preprocessing\n",
    "categorical_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "numeric_features = X_train.select_dtypes(include=np.number).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac7e615",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of numeric features\n",
    "X_train[numeric_features].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81341f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate distributions\n",
    "sns.histplot(data=X_train[\"luxury_assets_value\"], log_scale=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dec7de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter between predictor and target\n",
    "sns.catplot(y=X_train.income_annum, x=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2080cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missingness rates\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed dataset\n",
    "df.to_csv(\"data/loan_data_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e371a91f",
   "metadata": {},
   "source": [
    "# Processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for Numerical Features (Handle Missing -> Scale)\n",
    "numerical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler()),  # critical for KNN to normalize distance\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline for categorical features (Handle Missing -> One-Hot Encode)\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\n",
    "            \"onehot\",\n",
    "            OneHotEncoder(handle_unknown=\"ignore\", drop=\"if_binary\"),\n",
    "        ),  # Handles new categories in test set\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Combine transformers\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ],\n",
    "    remainder=\"passthrough\",  # Keep any other columns if defined\n",
    ")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7a0e01",
   "metadata": {},
   "source": [
    "# Model training and tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: kNN with Tuning\n",
    "print(\"\\n--- Training KNN Model (with GridSearchCV) ---\")\n",
    "\n",
    "# Define the model pipeline\n",
    "knn_pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"classifier\", KNeighborsClassifier())]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for KNN tuning\n",
    "knn_param_grid = {\n",
    "    \"classifier__n_neighbors\": np.arange(1, 21, 2),  # Test odd K values from 3 to 19\n",
    "    \"classifier__weights\": [\"uniform\", \"distance\"],\n",
    "}\n",
    "\n",
    "# Perform Grid Search Cross-Validation\n",
    "knn_grid_search = GridSearchCV(\n",
    "    knn_pipe, knn_param_grid, cv=5, scoring=\"f1\", n_jobs=-1, verbose=2\n",
    ")\n",
    "knn_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_knn = knn_grid_search.best_estimator_\n",
    "knn_predictions = best_knn.predict(X_test)\n",
    "print(f\"Best KNN Parameters: {knn_grid_search.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Tree with Tuning\n",
    "print(\"\\n--- Training Decision Tree Model (with GridSearchCV) ---\")\n",
    "\n",
    "# Define the model pipeline\n",
    "dt_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"classifier\", DecisionTreeClassifier(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the parameter grid for Decision Tree tuning\n",
    "dt_param_grid = {\n",
    "    \"classifier__max_depth\": np.arange(3, 11, 1),  # Test depths from 3 to 10\n",
    "    \"classifier__min_samples_split\": [2, 5, 10],\n",
    "    \"classifier__criterion\": [\"gini\", \"entropy\"],\n",
    "}\n",
    "\n",
    "# Perform Grid Search Cross-Validation\n",
    "dt_grid_search = GridSearchCV(\n",
    "    dt_pipe, dt_param_grid, cv=5, scoring=\"f1\", n_jobs=-1, verbose=2\n",
    ")\n",
    "dt_grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_dt = dt_grid_search.best_estimator_\n",
    "dt_predictions = best_dt.predict(X_test)\n",
    "print(f\"Best Decision Tree Parameters: {dt_grid_search.best_params_}\")\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607c39a",
   "metadata": {},
   "source": [
    "# Model comparative evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c08cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates key classification metrics.\"\"\"\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred),\n",
    "        \"Recall\": recall_score(y_true, y_pred),\n",
    "        \"F1-Score\": f1_score(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate metrics for both models\n",
    "knn_metrics = get_metrics(y_test, knn_predictions)\n",
    "dt_metrics = get_metrics(y_test, dt_predictions)\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "comparison_df = pd.DataFrame(\n",
    "    {\"KNN (Tuned)\": knn_metrics, \"Decision Tree (Tuned)\": dt_metrics}\n",
    ").T\n",
    "\n",
    "print(\"\\nModel Performance Comparison on Test Set\")\n",
    "print(comparison_df.to_markdown(floatfmt=\".4f\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac317b6e",
   "metadata": {},
   "source": [
    "# Feature importances (decision tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get feature names after preprocessing\n",
    "ohe_feature_names = (\n",
    "    best_dt.named_steps[\"preprocessor\"]\n",
    "    .named_transformers_[\"cat\"]\n",
    "    .named_steps[\"onehot\"]\n",
    "    .get_feature_names_out(categorical_features)\n",
    ")\n",
    "all_feature_names = numeric_features + ohe_feature_names.tolist()\n",
    "\n",
    "# 2. Extract importance scores\n",
    "dt_classifier = best_dt.named_steps[\"classifier\"]\n",
    "importances = dt_classifier.feature_importances_\n",
    "\n",
    "# 3. Create and sort DataFrame\n",
    "feature_importance_df = pd.DataFrame(\n",
    "    {\"Feature\": all_feature_names, \"Importance\": importances}\n",
    ").sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop Feature Importances (from Decision Tree)\")\n",
    "print(\"-\" * 50)\n",
    "print(feature_importance_df.to_markdown(floatfmt=\".4f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e281fe5",
   "metadata": {},
   "source": [
    "# Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e80f0",
   "metadata": {},
   "source": [
    "In loan approval, there are two types of critical errors:\n",
    "\n",
    "- Type I Error (false positive) --> Cost of error = Financial Loss (approving a loan to a high-risk applicant who defaults. The bank loses money.)\n",
    "- Type II error (false negative) --> Cost of error = Opportunity Cost (denying a loan to a low-risk applicant who would have repaid. The bank loses potential revenue.)\n",
    "\n",
    "**Scenario 1: Risk Aversion**\n",
    "\n",
    "If the bank is highly risk-averse and primarily concerned with minimizing financial losses from defaults, they should prioritize high Precision.\n",
    "A model with high Precision ensures that when it approves a loan, the chances of that loan being good are very high.\n",
    "The trade-off: The bank will inevitably deny some good applicants (more False Negatives), leading to lost business opportunities.\n",
    "\n",
    "**Scenario 2: Market Expansion**\n",
    "\n",
    "If the bank is in a market expansion phase and focused on maximizing the volume of loans while accepting slightly higher risk, they may prioritize high Recall.\n",
    "A model with high Recall ensures that almost all good applicants are approved.\n",
    "The trade-off: The bank will inevitably approve some high-risk applicants (more False Positives), leading to higher default rates.\n",
    "\n",
    "In our case, we don't have information about the bank's preference so we take a balanced approach by using the F1-Score, i.e., the harmonic mean of Precision and Recall. The F1-Score provides a single, balanced measure of the model's performance on the positive class (Loan Approved), penalizing models that perform well on one metric while poorly on the other.\n",
    "\n",
    "**Recommendation**   \n",
    "\n",
    "From the two models explored, we would endorse the tuned decision tree as it clearly outperforms the k-NN classifier in all relevant metrics (precision, recall and F1 score) by a noticeable margin. At the same time, it is a more transparent and auditable model which is critical for loan decision-making applications.\n",
    "\n",
    "The most influential factor for loan application outcome is the applicant's credit risk score. This finding shows that the bank should prioritize rigorous verification of the applicant's credit history and clearly define policy thresholds based on this factor.\n",
    "The loan term has the second highest impact (by a margin from credit risk score) which indicates that the bank should carefully consider optimal loan durations to minimise default rates.\n",
    "Other features like annual income and loan amount appear suspiciously insignificant, which casts a doubt on the quality and validity of the dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "validata_loan_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
